import json
import asyncio
import time
from core.providers.tts.dto.dto import SentenceType
from core.utils.util import get_string_no_punctuation_or_emoji, analyze_emotion
from loguru import logger
import re

TAG = __name__

emoji_map = {
    "neutral": "ğŸ˜¶",
    "happy": "ğŸ™‚",
    "laughing": "ğŸ˜†",
    "funny": "ğŸ˜‚",
    "sad": "ğŸ˜”",
    "angry": "ğŸ˜ ",
    "crying": "ğŸ˜­",
    "loving": "ğŸ˜",
    "embarrassed": "ğŸ˜³",
    "surprised": "ğŸ˜²",
    "shocked": "ğŸ˜±",
    "thinking": "ğŸ¤”",
    "winking": "ğŸ˜‰",
    "cool": "ğŸ˜",
    "relaxed": "ğŸ˜Œ",
    "delicious": "ğŸ¤¤",
    "kissy": "ğŸ˜˜",
    "confident": "ğŸ˜",
    "sleepy": "ğŸ˜´",
    "silly": "ğŸ˜œ",
    "confused": "ğŸ™„",
}


async def sendAudioMessage(conn, sentenceType, audios, text):
    # å»é™¤æ‹¬å·ä¸­çš„è¯­æ°”è¯
    text = await handle_text(text)
    # å‘é€å¥å­å¼€å§‹æ¶ˆæ¯
    if text is not None:
        emotion = analyze_emotion(text)
        emoji = emoji_map.get(emotion, "ğŸ™‚")  # é»˜è®¤ä½¿ç”¨ç¬‘è„¸
        await conn.websocket.send(
            json.dumps(
                {
                    "type": "llm",
                    "text": emoji,
                    "emotion": emotion,
                    "session_id": conn.session_id,
                }
            )
        )
    pre_buffer = False
    if conn.tts.tts_audio_first_sentence and text is not None:
        conn.logger.bind(tag=TAG).info(f"å‘é€ç¬¬ä¸€æ®µè¯­éŸ³: {text}")
        conn.tts.tts_audio_first_sentence = False
        pre_buffer = True

    await send_tts_message(conn, "sentence_start", text)

    await sendAudio(conn, audios, pre_buffer)

    await send_tts_message(conn, "sentence_end", text)

    # å‘é€ç»“æŸæ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯æœ€åä¸€ä¸ªæ–‡æœ¬ï¼‰
    if conn.llm_finish_task and sentenceType == SentenceType.LAST:
        await send_tts_message(conn, "stop", None)
        conn.client_is_speaking = False
        if conn.close_after_chat:
            await conn.close()


# æ’­æ”¾éŸ³é¢‘
async def sendAudio(conn, audios, pre_buffer=True):
    if audios is None or len(audios) == 0:
        return
    # æµæ§å‚æ•°ä¼˜åŒ–
    frame_duration = 60  # å¸§æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼ŒåŒ¹é… Opus ç¼–ç 
    start_time = time.perf_counter()
    play_position = 0
    last_reset_time = time.perf_counter()  # è®°å½•æœ€åçš„é‡ç½®æ—¶é—´

    # ä»…å½“ç¬¬ä¸€å¥è¯æ—¶æ‰§è¡Œé¢„ç¼“å†²
    if pre_buffer:
        pre_buffer_frames = min(3, len(audios))
        for i in range(pre_buffer_frames):
            await conn.websocket.send(audios[i])
        remaining_audios = audios[pre_buffer_frames:]
    else:
        remaining_audios = audios

    # æ’­æ”¾å‰©ä½™éŸ³é¢‘å¸§
    for opus_packet in remaining_audios:
        if conn.client_abort:
            break

        # æ¯åˆ†é’Ÿé‡ç½®ä¸€æ¬¡è®¡æ—¶å™¨
        if time.perf_counter() - last_reset_time > 60:
            await conn.reset_timeout()
            last_reset_time = time.perf_counter()

        # è®¡ç®—é¢„æœŸå‘é€æ—¶é—´
        expected_time = start_time + (play_position / 1000)
        current_time = time.perf_counter()
        delay = expected_time - current_time
        if delay > 0:
            await asyncio.sleep(delay)

        await conn.websocket.send(opus_packet)

        play_position += frame_duration


async def send_tts_message(conn, state, text=None):
    """å‘é€ TTS çŠ¶æ€æ¶ˆæ¯"""
    message = {"type": "tts", "state": state, "session_id": conn.session_id}
    if text is not None:
        message["text"] = text

    # TTSæ’­æ”¾ç»“æŸ
    if state == "stop":
        # æ’­æ”¾æç¤ºéŸ³
        tts_notify = conn.config.get("enable_stop_tts_notify", False)
        if tts_notify:
            stop_tts_notify_voice = conn.config.get(
                "stop_tts_notify_voice", "config/assets/tts_notify.mp3"
            )
            audios, _ = conn.tts.audio_to_opus_data(stop_tts_notify_voice)
            await sendAudio(conn, audios)
        # æ¸…é™¤æœåŠ¡ç«¯è®²è¯çŠ¶æ€
        conn.clearSpeakStatus()

    # å‘é€æ¶ˆæ¯åˆ°å®¢æˆ·ç«¯
    await conn.websocket.send(json.dumps(message))


async def send_stt_message(conn, text):
    end_prompt_str = conn.config.get("end_prompt", {}).get("prompt")
    if end_prompt_str and end_prompt_str == text:
        await send_tts_message(conn, "start")
        return

    """å‘é€ STT çŠ¶æ€æ¶ˆæ¯"""
    stt_text = get_string_no_punctuation_or_emoji(text)
    await conn.websocket.send(
        json.dumps({"type": "stt", "text": stt_text, "session_id": conn.session_id})
    )
    conn.client_is_speaking = True
    await send_tts_message(conn, "start")


"""
ç§»é™¤æ‹¬å·ä¸­çš„è¯­æ°”è¯
"""
async def handle_text(text):
    if not text or len(text) == 0:
        return text

    # 1. åˆ é™¤ä¸­æ–‡æ‹¬å·ï¼ˆï¼‰å’Œè‹±æ–‡æ‹¬å·()åŠå…¶ä¸­å†…å®¹
    text = re.sub(r'ï¼ˆ[^ï¼‰]*ï¼‰|$[^)]*$', '', text)

    # 2. åˆ é™¤æˆå¯¹ä½†ä¸­é—´ä¸ºç©ºçš„åŒå¼•å·ï¼ˆåŒ…æ‹¬ä¸­æ–‡ã€è‹±æ–‡å¼•å·ï¼‰
    text = re.sub(r'["â€œ"][\sâ€œâ€]*["â€]', '', text)

    # 3. åˆ é™¤ä¸æˆå¯¹çš„å•ä¸ªå¼•å·/æ‹¬å·
    stack = []
    chars = list(text)
    quote_pairs = {'"': '"', 'â€œ': 'â€', 'â€˜': 'â€™'}
    for i, ch in enumerate(chars):
        if ch in quote_pairs:
            stack.append((i, ch))
        elif ch in quote_pairs.values():
            if stack and quote_pairs.get(stack[-1][1]) == ch:
                stack.pop()
            else:
                # å¦‚æœæ˜¯å­¤ç«‹å³å¼•å·ï¼Œæ ‡è®°ä¸ºå¾…åˆ é™¤
                chars[i] = '\x00DELETE\x00'

    # æ ‡è®°æ‰€æœ‰æœªé—­åˆçš„å·¦å¼•å·ä¸ºå¾…åˆ é™¤
    for pos, _ in stack:
        chars[pos] = '\x00DELETE\x00'

    # æ„å»ºæ–°å­—ç¬¦ä¸²ï¼Œç§»é™¤æ‰€æœ‰æ ‡è®°ä¸º DELETE çš„å­—ç¬¦
    cleaned_text = ''.join([c for c in chars if c != '\x00DELETE\x00'])

    # 4. å†æ¬¡åˆ é™¤å¯èƒ½æ®‹ç•™çš„ç‹¬ç«‹ç¬¦å·ï¼ˆå¢å¼ºç‰ˆï¼‰
    # åŒ¹é…ï¼šå•ç‹¬çš„å¼•å·ã€æ‹¬å·ã€çœç•¥å·ç­‰
    cleaned_text = re.sub(r'(?<![\wâ€œâ€œâ€â€˜â€™])["â€œâ€â€˜â€™)(â€¦â‹¯â€¦ï½~]|(?:\.\.\.)|(?:\u2026)|(?:\u2026\u2026*)', '', cleaned_text)

    # 5. æœ€ç»ˆå»é™¤é¦–å°¾ç©ºç™½
    return cleaned_text.strip()